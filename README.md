# ğŸš– NYC Taxi Data Pipeline

![Snowflake](https://img.shields.io/badge/Snowflake-Data_Warehouse-blue)
![dbt](https://img.shields.io/badge/dbt-Transformations-orange)
![Python](https://img.shields.io/badge/Python-Ingestion-yellow)
![Status](https://img.shields.io/badge/Status-In_Development-green)

## ğŸ“‹ RÃ©sumÃ© du Projet

Pipeline ELT moderne conÃ§u pour traiter et analyser plus de **40 millions de trajets** de taxis new-yorkais (2024-2025).
L'objectif est de transformer des donnÃ©es brutes (Parquet) en mÃ©triques business actionnables (revenus, patterns de trafic, performance des zones) via une architecture Data Warehouse robuste.

## ğŸ—ï¸ Architecture Technique

**Architecture Medallion (Multi-couches) :**

1. **Ingestion (Python/S3)** : Chargement automatisÃ© des fichiers Parquet mensuels vers Snowflake.
2. **RAW (Bronze)** : Stockage immuable des donnÃ©es brutes.
3. **STAGING (Silver - dbt)** : Nettoyage, dÃ©doublonnage, typage et tests de qualitÃ© (Data Quality).
4. **DATA MARTS (Gold - dbt)** : Tables dimensionnelles et faits optimisÃ©s pour l'analytique (BI).

## ğŸ› ï¸ Stack Technologique

* **Data Warehouse** : Snowflake (Scale-up/Scale-out compute)
* **Transformation** : dbt Core (SQL-based transformation & testing)
* **Langage** : Python 3.9+ & SQL
* **Orchestration** : GitHub Actions (CI/CD)
* **Version Control** : Git (Feature Branch Workflow)

## ğŸš€ Comment DÃ©marrer

1. Cloner le repo
2. Installer les dÃ©pendances : `pip install -r requirements.txt`
3. Configurer les profils dbt (`~/.dbt/profiles.yml`)
4. Lancer le pipeline : `dbt run`
